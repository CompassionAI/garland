84000-parallel-sentences-no-registers-valid-from-train:
  # The name of the dataset loader file to use (via the datasets library)
  dataset_loader: cai_garland/data/parallel_dataset_loader_hf.py

  # The name of the dataset to load from the loader file
  dataset_config: no_registers_no_splits

  # Source language id for translation
  source_lang: bo

  # Source language id for translation
  target_lang: en

  # The token to force as the first generated token after the 'decoder_start_token_id'. Useful for multilingual models
  #   like mBART where the first generated token needs to be the target language token. Usually it is the target
  #   language token
  forced_bos_token: ~

  # Name of the validation split to use in the overall dataset (defaults to "validation" if omitted)
  #   If set to train, will split the training data according to validation_sampling_rate
  validation_split_name: train
  validation_sampling_rate: 0.005

  # Name of the validation split to use in the overall dataset (defaults to "test" if omitted, skipped if ~)
  test_split_name: ~

  # Rate at which to subsample the validation data. Performed _after_ the register rebalancing, if any. With rebalancing,
  #   the approximate final size of the evaluation set is given by the following:
  #
  #     (1 + validation_register_rebalance_frac) * (fraction of register data) * validation_subsampling_rate
  #
  #   with the register data balance as specified by validation_register_rebalance_frac, if any.
  #
  # Can be none to avoid subsampling.
  validation_subsampling_rate: ~